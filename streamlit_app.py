'''
Interface de UsuÃ¡rio (Frontend) para o Agent_BI.
'''
import streamlit as st
import requests
import uuid
import pandas as pd
from core.auth import login, sessao_expirada

# --- AutenticaÃ§Ã£o ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated or sessao_expirada():
    st.session_state.authenticated = False
    login()
else:
    # --- ConfiguraÃ§Ã£o da PÃ¡gina ---
    st.set_page_config(page_title="Agent_BI", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸ“Š Agent_BI - Assistente Inteligente")

    # --- Logout Button ---
    with st.sidebar:
        st.write(f"Bem-vindo, {st.session_state.get('username', '')}!")
        if st.button("Logout"):
            st.session_state.authenticated = False
            st.session_state.username = ""
            st.session_state.role = ""
            # Clear chat history on logout
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": {
                        "type": "text",
                        "content": "VocÃª foi desconectado. FaÃ§a login para continuar."
                    }
                }
            ]
            st.rerun()


    # --- Constantes e Estado da SessÃ£o ---
    API_URL = "http://127.0.0.1:8000/api/v1/query"

    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": {
                    "type": "text",
                    "content": "OlÃ¡! Como posso ajudar vocÃª com seus dados hoje?"
                }
            }
        ]

    # --- FunÃ§Ãµes de InteraÃ§Ã£o ---
    def query_backend(user_input: str):
        '''Envia a query para a API e lida com a resposta.'''
        # ğŸ“ GARANTIR que a pergunta do usuÃ¡rio seja sempre preservada
        user_message = {"role": "user", "content": {"type": "text", "content": user_input}}
        st.session_state.messages.append(user_message)

        # ğŸ” LOG da pergunta (removido print para evitar problemas de encoding)
        # print(f"USER QUESTION ADDED: '{user_input}' - Total messages: {len(st.session_state.messages)}")

        with st.spinner("O agente estÃ¡ a pensar..."):
            try:
                payload = {"user_query": user_input, "session_id": st.session_state.session_id}
                response = requests.post(API_URL, json=payload, timeout=120)
                response.raise_for_status()
                agent_response = response.json()

                # âœ… GARANTIR estrutura correta da resposta
                assistant_message = {"role": "assistant", "content": agent_response}
                st.session_state.messages.append(assistant_message)

                # ğŸ” LOG da resposta (removido print para evitar problemas de encoding)
                # print(f"AGENT RESPONSE ADDED: Type={agent_response.get('type', 'unknown')} - Total messages: {len(st.session_state.messages)}")

            except requests.exceptions.Timeout:
                error_content = {"type": "error", "content": "Tempo limite esgotado. O servidor pode estar sobrecarregado. Tente novamente."}
                st.session_state.messages.append({"role": "assistant", "content": error_content})
            except requests.exceptions.ConnectionError:
                error_content = {"type": "error", "content": "NÃ£o foi possÃ­vel conectar ao servidor. Verifique se o backend estÃ¡ rodando."}
                st.session_state.messages.append({"role": "assistant", "content": error_content})
            except requests.exceptions.RequestException as e:
                error_content = {"type": "error", "content": f"Erro na comunicaÃ§Ã£o com o servidor: {str(e)}"}
                st.session_state.messages.append({"role": "assistant", "content": error_content})

        st.rerun()

    # --- RenderizaÃ§Ã£o da Interface ---
    # ğŸ” DEBUG: Mostrar histÃ³rico de mensagens na sidebar (apenas para desenvolvimento)
    with st.sidebar:
        st.write(f"**Total de mensagens:** {len(st.session_state.messages)}")
        if st.checkbox("Mostrar histÃ³rico debug"):
            for i, msg in enumerate(st.session_state.messages):
                st.write(f"**{i+1}. {msg['role'].title()}:**")
                content_preview = str(msg.get('content', {}))[:100] + "..." if len(str(msg.get('content', {}))) > 100 else str(msg.get('content', {}))
                st.write(f"{content_preview}")

    # ğŸ’¬ RENDERIZAR histÃ³rico de conversas
    for i, msg in enumerate(st.session_state.messages):
        try:
            with st.chat_message(msg["role"]):
                response_data = msg.get("content", {})

                # âœ… Garantir que response_data seja um dicionÃ¡rio
                if not isinstance(response_data, dict):
                    response_data = {"type": "text", "content": str(response_data)}

                response_type = response_data.get("type", "text")
                content = response_data.get("content", "ConteÃºdo nÃ£o disponÃ­vel")

            # ğŸ” DEBUG: Log de renderizaÃ§Ã£o (removido print para evitar problemas)
            # if msg["role"] == "user":
            #     print(f"RENDERING USER MSG {i+1}: '{content}'")
            # else:
            #     print(f"RENDERING ASSISTANT MSG {i+1}: Type={response_type}")
            
            # ğŸ“ˆ RENDERIZAR GRÃFICOS
            if response_type == "chart":
                import json
                import plotly.graph_objects as go

                # ğŸ“ Mostrar contexto da pergunta que gerou o grÃ¡fico
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                try:
                    if isinstance(content, str):
                        # Se content Ã© string JSON, parse para objeto
                        chart_data = json.loads(content)
                    else:
                        # Se content jÃ¡ Ã© dict, usa diretamente
                        chart_data = content

                    # Cria figura Plotly a partir do JSON
                    fig = go.Figure(chart_data)
                    st.plotly_chart(fig, use_container_width=True)
                    st.success("âœ… GrÃ¡fico gerado com sucesso!")
                except Exception as e:
                    st.error(f"Erro ao renderizar grÃ¡fico: {e}")
                    st.write("Dados do grÃ¡fico:", content)
            elif response_type == "data" and isinstance(content, list):
                # ğŸ“ Mostrar contexto da pergunta que gerou os dados
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                if content:
                    st.dataframe(pd.DataFrame(content))
                    st.info(f"ğŸ“Š {len(content)} registros encontrados")
                else:
                    st.warning("âš ï¸ Nenhum dado encontrado para a consulta.")
            elif response_type == "clarification":
                st.markdown(content.get("message"))
                choices = content.get("choices", {})
                for choice_category, choice_list in choices.items():
                    for choice in choice_list:
                        if st.button(choice, key=f"btn_{choice}_{uuid.uuid4()}"):
                            query_backend(choice)
            else:
                # ğŸ“ Para respostas de texto, tambÃ©m mostrar contexto se disponÃ­vel
                user_query = response_data.get("user_query")
                if user_query and msg["role"] == "assistant":
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                st.write(content)

        except Exception as e:
            # âŒ Tratamento de erro na renderizaÃ§Ã£o
            st.error(f"Erro ao renderizar mensagem {i+1}: {str(e)}")
            st.write(f"Dados da mensagem: {msg}")

    if prompt := st.chat_input("FaÃ§a sua pergunta..."):
        query_backend(prompt)
