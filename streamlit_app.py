'''
Interface de UsuÃ¡rio (Frontend) para o Agent_BI.
VersÃ£o integrada que nÃ£o depende de API externa.
'''
import streamlit as st
import uuid
import pandas as pd
import logging
from core.auth import login, sessao_expirada

# ImportaÃ§Ãµes do backend para integraÃ§Ã£o direta
try:
    from core.graph.graph_builder import GraphBuilder
    from core.config.settings import settings
    from core.llm_adapter import OpenAILLMAdapter
    from core.connectivity.parquet_adapter import ParquetAdapter
    from core.agents.code_gen_agent import CodeGenAgent
    from langchain_core.messages import HumanMessage
    BACKEND_AVAILABLE = True
except Exception as e:
    logging.warning(f"Backend components nÃ£o disponÃ­veis: {e}")
    BACKEND_AVAILABLE = False

# --- AutenticaÃ§Ã£o ---
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated or sessao_expirada():
    st.session_state.authenticated = False
    login()
else:
    # --- ConfiguraÃ§Ã£o da PÃ¡gina ---
    st.set_page_config(page_title="Agent_BI", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸ“Š Agent_BI - Assistente Inteligente")

    # --- InicializaÃ§Ã£o do Backend Integrado ---
    @st.cache_resource
    def initialize_backend():
        """Inicializa os componentes do backend uma Ãºnica vez"""
        debug_info = []

        # Debug 1: Verificar imports
        debug_info.append(f"BACKEND_AVAILABLE: {BACKEND_AVAILABLE}")
        if not BACKEND_AVAILABLE:
            with st.sidebar:
                st.error("âŒ Imports do backend falharam")
                st.write("Componentes nÃ£o carregados:")
                st.code("LangGraph, OpenAI, ParquetAdapter, etc.")
            return None

        try:
            # Debug 2: Verificar secrets
            api_key = None
            secrets_status = "âŒ Falhou"
            try:
                api_key = st.secrets.get("OPENAI_API_KEY")
                if api_key and api_key.startswith("sk-"):
                    secrets_status = "âœ… OK"
                    debug_info.append(f"Secrets OpenAI: OK ({api_key[:10]}...)")
                else:
                    debug_info.append(f"Secrets OpenAI: InvÃ¡lida")
            except Exception as e:
                debug_info.append(f"Secrets erro: {e}")

            # Debug 3: Fallback para settings
            if not api_key or not api_key.startswith("sk-"):
                try:
                    api_key = settings.OPENAI_API_KEY.get_secret_value()
                    debug_info.append(f"Settings OpenAI: OK")
                except Exception as e:
                    debug_info.append(f"Settings erro: {e}")

            if not api_key or not api_key.startswith("sk-"):
                raise ValueError("OPENAI_API_KEY nÃ£o encontrada em secrets nem settings")

            # Debug 4: Inicializar LLM
            debug_info.append("Inicializando LLM...")
            llm_adapter = OpenAILLMAdapter(api_key=api_key)
            debug_info.append("âœ… LLM OK")

            # Debug 5: Inicializar Parquet
            debug_info.append("Inicializando Parquet...")
            parquet_adapter = ParquetAdapter(file_path="data/parquet/admatao.parquet")
            debug_info.append("âœ… Parquet OK")

            # Debug 6: Inicializar CodeGen
            debug_info.append("Inicializando CodeGen...")
            code_gen_agent = CodeGenAgent(llm_adapter=llm_adapter)
            debug_info.append("âœ… CodeGen OK")

            # Debug 7: Construir Grafo
            debug_info.append("Construindo grafo...")
            graph_builder = GraphBuilder(
                llm_adapter=llm_adapter,
                parquet_adapter=parquet_adapter,
                code_gen_agent=code_gen_agent
            )
            agent_graph = graph_builder.build()
            debug_info.append("âœ… Grafo OK")

            debug_info.append("ğŸ‰ Backend inicializado com sucesso!")

            return {
                "llm_adapter": llm_adapter,
                "parquet_adapter": parquet_adapter,
                "code_gen_agent": code_gen_agent,
                "agent_graph": agent_graph
            }

        except Exception as e:
            debug_info.append(f"âŒ ERRO: {str(e)}")

            # Mostrar debug completo na sidebar
            with st.sidebar:
                st.error("ğŸš¨ Backend Error")
                st.write("**Debug Log:**")
                for info in debug_info:
                    if "âœ…" in info:
                        st.success(info)
                    elif "âŒ" in info:
                        st.error(info)
                    else:
                        st.info(info)

                st.write("**Erro Completo:**")
                st.code(str(e))

            return None

    # Inicializar backend
    backend_components = initialize_backend()

    # Salvar no session_state para acesso em outras partes
    if backend_components:
        st.session_state.backend_components = backend_components
        with st.sidebar:
            st.success("âœ… Backend inicializado!")
    else:
        st.session_state.backend_components = None
        with st.sidebar:
            st.error("âŒ Backend falhou")

    # --- Logout Button ---
    with st.sidebar:
        st.write(f"Bem-vindo, {st.session_state.get('username', '')}!")
        if st.button("Logout"):
            st.session_state.authenticated = False
            st.session_state.username = ""
            st.session_state.role = ""
            # Clear chat history on logout
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": {
                        "type": "text",
                        "content": "VocÃª foi desconectado. FaÃ§a login para continuar."
                    }
                }
            ]
            st.rerun()


    # --- Estado da SessÃ£o ---

    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": {
                    "type": "text",
                    "content": "OlÃ¡! Como posso ajudar vocÃª com seus dados hoje?"
                }
            }
        ]

    # --- FunÃ§Ãµes de InteraÃ§Ã£o ---
    def query_backend(user_input: str):
        '''Processa a query diretamente usando o backend integrado.'''
        # ğŸ“ GARANTIR que a pergunta do usuÃ¡rio seja sempre preservada
        user_message = {"role": "user", "content": {"type": "text", "content": user_input}}
        st.session_state.messages.append(user_message)

        with st.spinner("O agente estÃ¡ a pensar..."):
            try:
                if not backend_components or not backend_components.get("agent_graph"):
                    # Fallback: resposta simples se backend nÃ£o disponÃ­vel
                    agent_response = {
                        "type": "text",
                        "content": f"âš ï¸ Backend nÃ£o disponÃ­vel. Pergunta recebida: '{user_input}'\n\nPor favor, configure a chave OPENAI_API_KEY nos secrets do Streamlit Cloud para ativar todas as funcionalidades.",
                        "user_query": user_input
                    }
                else:
                    # Usar backend integrado (similar ao main.py)
                    initial_state = {"messages": [HumanMessage(content=user_input)]}
                    final_state = backend_components["agent_graph"].invoke(initial_state)
                    agent_response = final_state.get("final_response", {})

                    # Garantir que a resposta inclui informaÃ§Ãµes da pergunta
                    if "user_query" not in agent_response:
                        agent_response["user_query"] = user_input

                # âœ… GARANTIR estrutura correta da resposta
                assistant_message = {"role": "assistant", "content": agent_response}
                st.session_state.messages.append(assistant_message)

                # ğŸ” LOG da resposta (removido print para evitar problemas de encoding)
                # print(f"AGENT RESPONSE ADDED: Type={agent_response.get('type', 'unknown')} - Total messages: {len(st.session_state.messages)}")

            except Exception as e:
                # Tratamento de erro local
                error_content = {
                    "type": "error",
                    "content": f"âŒ Erro ao processar consulta: {str(e)}\n\nVerifique se a chave OPENAI_API_KEY estÃ¡ configurada corretamente nos secrets."
                }
                st.session_state.messages.append({"role": "assistant", "content": error_content})

        st.rerun()

    # --- RenderizaÃ§Ã£o da Interface ---
    # ğŸ” DEBUG: Mostrar histÃ³rico de mensagens na sidebar (apenas para desenvolvimento)
    with st.sidebar:
        st.write(f"**Total de mensagens:** {len(st.session_state.messages)}")
        if st.checkbox("Mostrar histÃ³rico debug"):
            for i, msg in enumerate(st.session_state.messages):
                st.write(f"**{i+1}. {msg['role'].title()}:**")
                content_preview = str(msg.get('content', {}))[:100] + "..." if len(str(msg.get('content', {}))) > 100 else str(msg.get('content', {}))
                st.write(f"{content_preview}")

    # ğŸ’¬ RENDERIZAR histÃ³rico de conversas
    for i, msg in enumerate(st.session_state.messages):
        try:
            with st.chat_message(msg["role"]):
                response_data = msg.get("content", {})

                # âœ… Garantir que response_data seja um dicionÃ¡rio
                if not isinstance(response_data, dict):
                    response_data = {"type": "text", "content": str(response_data)}

                response_type = response_data.get("type", "text")
                content = response_data.get("content", "ConteÃºdo nÃ£o disponÃ­vel")

            # ğŸ” DEBUG: Log de renderizaÃ§Ã£o (removido print para evitar problemas)
            # if msg["role"] == "user":
            #     print(f"RENDERING USER MSG {i+1}: '{content}'")
            # else:
            #     print(f"RENDERING ASSISTANT MSG {i+1}: Type={response_type}")
            
            # ğŸ“ˆ RENDERIZAR GRÃFICOS
            if response_type == "chart":
                import json
                import plotly.graph_objects as go

                # ğŸ“ Mostrar contexto da pergunta que gerou o grÃ¡fico
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                try:
                    if isinstance(content, str):
                        # Se content Ã© string JSON, parse para objeto
                        chart_data = json.loads(content)
                    else:
                        # Se content jÃ¡ Ã© dict, usa diretamente
                        chart_data = content

                    # Cria figura Plotly a partir do JSON
                    fig = go.Figure(chart_data)
                    st.plotly_chart(fig, use_container_width=True)
                    st.success("âœ… GrÃ¡fico gerado com sucesso!")
                except Exception as e:
                    st.error(f"Erro ao renderizar grÃ¡fico: {e}")
                    st.write("Dados do grÃ¡fico:", content)
            elif response_type == "data" and isinstance(content, list):
                # ğŸ“ Mostrar contexto da pergunta que gerou os dados
                user_query = response_data.get("user_query")
                if user_query:
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                if content:
                    st.dataframe(pd.DataFrame(content))
                    st.info(f"ğŸ“Š {len(content)} registros encontrados")
                else:
                    st.warning("âš ï¸ Nenhum dado encontrado para a consulta.")
            elif response_type == "clarification":
                st.markdown(content.get("message"))
                choices = content.get("choices", {})
                for choice_category, choice_list in choices.items():
                    for choice in choice_list:
                        if st.button(choice, key=f"btn_{choice}_{uuid.uuid4()}"):
                            query_backend(choice)
            else:
                # ğŸ“ Para respostas de texto, tambÃ©m mostrar contexto se disponÃ­vel
                user_query = response_data.get("user_query")
                if user_query and msg["role"] == "assistant":
                    st.caption(f"ğŸ“ Pergunta: {user_query}")

                st.write(content)

        except Exception as e:
            # âŒ Tratamento de erro na renderizaÃ§Ã£o
            st.error(f"Erro ao renderizar mensagem {i+1}: {str(e)}")
            st.write(f"Dados da mensagem: {msg}")

    if prompt := st.chat_input("FaÃ§a sua pergunta..."):
        query_backend(prompt)
